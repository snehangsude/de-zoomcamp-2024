{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1093647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, LongType, DoubleType, IntegerType\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b173972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/03 08:44:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[4]\").appName(\"homework\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64850973",
   "metadata": {},
   "source": [
    "# Q1: Version of spark.\n",
    "\n",
    "\n",
    "Interestingly, you can do both `spark.version` after defining the spark object. Else run `pyspark.__version__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f00571a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f48b69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f03490b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1898240"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_fhv = StructType([\n",
    "    StructField(\"dispatching_base_num\", StringType(), True),\n",
    "    StructField(\"pickup_datetime\", TimestampType(), True),\n",
    "    StructField(\"dropOff_datetime\", TimestampType(), True),\n",
    "    StructField(\"PUlocationID\", IntegerType(), True),\n",
    "    StructField(\"DOlocationID\", IntegerType(), True),\n",
    "    StructField(\"SR_Flag\", StringType(), True),\n",
    "    StructField(\"Affiliated_base_number\", StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").schema(schema_fhv).csv(\"./\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b89de28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cae3a890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 09:11:39 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 7\n",
      "CSV file: file:///home/desnehangsu/notebooks/gather_data.sh\n",
      "24/03/03 09:11:39 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 7\n",
      "CSV file: file:///home/desnehangsu/notebooks/batch_pyspark.ipynb\n",
      "24/03/03 09:11:39 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 7\n",
      "CSV file: file:///home/desnehangsu/notebooks/load_to_parq.ipynb\n",
      "24/03/03 09:11:39 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 7\n",
      "CSV file: file:///home/desnehangsu/notebooks/Untitled.ipynb\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhv/2019/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b10ad213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1898144"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = spark.read.parquet('./fhv/2019/')\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "577ebaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2= data.withColumn(\"pickup_date\", F.to_date('pickup_datetime')).select(\"pickup_date\")\n",
    "q2 = q2.filter(q2.pickup_date == datetime.strptime('2019-10-15', '%Y-%m-%d').date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c802cf",
   "metadata": {},
   "source": [
    "## Q2: No. of trips in Oct 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33ad20db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433be96",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e3eb5bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18326f94",
   "metadata": {},
   "source": [
    "# 04: Highest ride time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b0b0bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------+\n",
      "|    pickup_datetime|   dropOff_datetime|        ride_time|\n",
      "+-------------------+-------------------+-----------------+\n",
      "|2019-10-11 18:00:00|2091-10-11 18:30:00|         631152.5|\n",
      "|2019-10-28 09:00:00|2091-10-28 09:30:00|         631152.5|\n",
      "|2019-10-31 23:46:33|2029-11-01 00:13:00|87672.44083333333|\n",
      "+-------------------+-------------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "q3 = data \\\n",
    "        .withColumn(\"ride_time\", (F.unix_timestamp('dropOff_datetime') - F.unix_timestamp('pickup_datetime'))/3600) \\\n",
    "        .select('pickup_datetime', 'dropOff_datetime', 'ride_time').sort(F.desc('ride_time'))\n",
    "q3.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf66ac7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0ee07ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('LocationID', IntegerType(), True), StructField('Borough', StringType(), True), StructField('Zone', StringType(), True), StructField('service_zone', StringType(), True)])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_lookup = StructType([\n",
    "    StructField(\"LocationID\", IntegerType(), True),\n",
    "    StructField(\"Borough\", StringType(), True),\n",
    "    StructField(\"Zone\", StringType(), True),\n",
    "    StructField(\"service_zone\", StringType(), True),\n",
    "])\n",
    "\n",
    "misc = spark.read.option(\"header\", \"true\").schema(schema_lookup).csv('taxi_zone_lookup.csv')\n",
    "misc.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e9038d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4 = data.join(misc, data.PUlocationID == misc.LocationID, \"inner\").select(\n",
    "    \"Borough\", \"Zone\", \"pickup_datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "657ae40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_ans = q4.groupBy(\"Zone\").count().sort(F.asc(\"count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f32982",
   "metadata": {},
   "source": [
    "# Q6: Least frequent zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e41c3c38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                Zone|count|\n",
      "+--------------------+-----+\n",
      "|         Jamaica Bay|    1|\n",
      "|Governor's Island...|    2|\n",
      "| Green-Wood Cemetery|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "q4_ans.show(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
